% !TeX spellcheck = en_US
\chapter{Introduction}

This chapter first gives the context of the thesis and introduces the research problem the thesis addresses. Furthermore, this chapter discusses the research questions the thesis is trying to answer and what approaches the thesis adopts. In addition, this chapter also gives a short introduction to the structure of the thesis.

\section{Background}

\glspl{amr} have gained enormous significance in automated factories. Recent developments in robotics and \gls{ai} have enabled the \gls{amr} to operate with autonomy. This requires the \glspl{amr} to run computation- and memory-intensive algorithms related to image processing, path planning, \gls{slam}, and learning \cite{Saeik2021}. However, \citeauthor*{Baxi2022} point out this poses a challenge for the robot's onboard system, which has limited computational capabilities due to size and cost limitation as well as battery life. Furthermore, these algorithms are time-sensitive and can cause operational failure for the \glspl{amr} if the latency restrictions cannot be satisfied. It becomes essential for large automated factories using \glspl{amr} to address this problem. 

% Maybe mention Human-Robot Collaboration?

\begin{figure}[htb]
    \centering

    \includegraphics[width=120mm]{figures/setup/amr_offloading.png}
    \caption{Offloading pipeline between \gls{amr} and edge computer}

    \label{fig:amr_offloading}
\end{figure}

\gls{mec} as an evolution of \gls*{mcc} brings application hosting from data centers down to the edge of the network, where the data were initially collected, to achieve low latency and bandwidth efficiency \cite{Lin2019}. For latency-sensitive tasks on \glspl{amr}, such as perception and navigation, \gls{mec} offers an opportunity to enable the \glspl{amr} with limited resources by offloading costly computation tasks to the edge, while only a small portion of the computation remains on the \gls{amr}'s on-board system. A full offloading pipeline for \glspl{amr} is illustrated in figure~\cref{fig:amr_offloading}.


However, depending on the application scenarios, offloading certain tasks from the \glspl{amr} to the edge at all times may not be possible, beneficial or even feasible due to the network's latency, dynamic network changes, and resource availability. \citeauthor*{Baxi2022} point out that a simple perception task using an RGB-D camera can cause over 100 ms sensing-to-actuation round-trip latency and over 50 MBytes per second network bandwidth usage. On the other hand, offloading computational workloads to the edge could also impact the \gls{amr}'s safety, availability as well as on-board resources. The exact influence on the robotic system will depend on the chosen offloading strategy. Therefore, it is necessary to investigate the effects of certain offloading strategies on the \gls{amr}'s safety, availability, and task performance.

\section{Research Problem}

This thesis first implements an offloading framework for robot perception and analyzes the effects of different offloading strategies, using \gls{ros} \cite{Macenski2022}. More specifically, this thesis considers a 2D object detection task using YOLOv5 network, proposed by \citeauthor*{Jocher2020}. YOLOv5n, a smaller variant of the perception network, will be deployed on the \gls{amr}'s on-board system, while the edge counterpart uses a more accurate but also more complex variant, e.g., YOLOv5l. The environment is an industrial warehouse containing human objects as obstacles. The \glspl{amr} are equipped with camera sensors and use the native \gls{ros} navigation stack, proposed by \citeauthor*{Macenski2020} to navigate from a user-defined route. 

This thesis first investigates offloading strategies with different offloading ratios. The \gls{amr} offloads a portion of the incoming frames from the camera to the edge computer with different offloading ratios incrementing from 0 percent to 100 percent with a stepping of 10 percent, i.e., the \gls{amr} offloads 10, 20, ..., 90 percent of the incoming frames to the edge computer. At 0 percent, the \gls{amr} does not offload at all to the edge computer and only relies on its onboard resources. At 100 percent, the \gls{amr} does not perform any local computation and only relies on the computation output of the edge computer. This step aims to investigate the influence of different offloading strategies on the performance of the perception task and the resource usage of the \gls{amr} and the edge computer as well as the network. 

% Then, this thesis carries on to implement a decision-making offloading strategy depending on runtime parameters, such as latency and \gls{amr}'s CPU usage and power consumption. This strategy is a simplified variant of the algorithm proposed by \citeauthor*{Ning2019} with a goal of minimizing latency and additional constraints subjected to power consumption and network bandwidth. 

This thesis evaluates the aforementioned offloading strategies regarding different metrics such as the CPU usage and power consumption of the \gls{amr}, the network bandwidth in use, and the mean average precision of the 2D object detection algorithm for human obstacles. The offloading strategies are first evaluated in simulation and later on in real robotic systems. With the results from these experiments, this thesis is trying to answer the following research questions: What effects do the aforementioned offloading strategies have on the specified metrics? Furthermore, this thesis is trying to answer the question: If and how the effects of different offloading strategies vary under different circumstances and if they have any (application-specific) constraints.

% Finally, this thesis is trying to gain insights if more complex strategies to achieve better results on the metrics. 

\section{Methodology}


