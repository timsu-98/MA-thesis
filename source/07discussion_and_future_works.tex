\chapter{Conclusion and Future Works}\label{ch:conclusion}

% ---------------------------------------------------------------
\section{Summary and Discussion}\label{sec:conclusion:discussion}
% ---------------------------------------------------------------

This thesis investigates the influence of different offloading strategies on important metrics. This thesis is built on the underlying assumptions that the \gls{amr} has limited computation and energy resources on its onboard system and the edge computer has abundant resources. Therefore, offloading some computation tasks to the edge computer can alleviate the situation. As an essential and computationally expensive task, object detection is used as the offloaded task. The state-of-art object detection pre-trained models are used to carry out the experiments. A complete offloading and evaluation pipeline is implemented to investigate the research questions. Different offloading strategies are implemented. Various metrics of the object detection task and the \gls{amr}'s onboard system are identified and defined. Furthermore, an appropriate evaluation method is chosen for the metrics. 

The experiments are first carried out in simulation to ensure the performance and robustness of the implementation. After simulation experiments, the \gls{rtt} is identified as an important factor for the performance of the object detection task. Therefore, it is used as a criterion for offloading decision in the decision making strategy. Finally, the experiments are conducted using a robotic system and an edge computer. The experiments are also carried out with both Ethernet and \gls{wifi} connections. The results from the experiments show that the performance of object detection task is also highly dependent on the available network bandwidth between the \gls{amr} and the edge computer. When the network bandwidth is enough for the offloaded task, it makes more sense for the \glspl{amr} to offload the task to the edge. This not only improves the task performance, e.g., higher processed frame rate, better \gls{map}, etc, but also reduces the resource usage on the \gls{amr}, e.g., \gls{cpu} usage and power consumption. This is beneficial for the \glspl{amr} in many ways. First, better performance of the object detection task will improve the \gls{amr}'s perception of the environment. More accurate perception makes the \glspl{amr} less unlikely to collide with obstacles. Higher frame rate allows the \glspl{amr} to adapt earlier changes to its behavior. These improvements will allow the \glspl{amr} to operate more safely. Moreover, by offloading the computationally expensive tasks to the edge computer, the \glspl{amr} have more available onboard resources, e.g., CPU cycles, battery life. This ensures an efficient operation and increases the avalability of the \glspl{amr}. Furthermore, with the more onboard resources freed up, the \glspl{amr} can use them for other safety-critical tasks onboard, e.g., \gls{slam}, navigation, etc. This also increases the safety of the \glspl{amr} indirectly.

However, if the network bandwidth is constrained, offloading all of the task may cause network congestion. The network delay of the edge perception will increase drastically and the performance of the object detection task of the images processed by edge computer will deteriorate. Under heavy load, the edge computer can only return a small number of processed detection with high network latency. In this case, the detection processed by the edge is essentially unusable. Moreover, if the network is bogarted by the offloaded task, other data cannot be transmitted over the network, which can be essential for other tasks of the \glspl{amr}, e.g., navigation, emergency control, etc. Therefore, the safety of the \glspl{amr} can be affected. However, offloading a portion of the object detection task within the limits of the network bandwidth will increase the performance of the object detection task and reduce the usage of the onboard resources. How much of the task should be offloaded to the edge computer is also dependent on the available network bandwidth and the available resources onboard. This can vary among different machines. In general, the offloading strategy can be considered as a compromise between the available onboard resources and the available network bandwidth. 

The thesis also implements a dynamic offloading strategy that uses the states of the onboard system and the network to decide whether to offload. The \gls{rtt} is used as a criterion for offloading decision. As mentioned in (TODO: add reference here), \gls{rtt} consists of the network latency and the inference time. This value represents both the computation capacities of the system and the network condition. If the system does not have enough computation resources, it will take more time to do the inference and thus cause the \gls{rtt} to increase. If the network is congested, the network latency of the task will increase because the task will start to queue. Therefore, the dynamic offloading strategy uses \gls{rtt} as a criterion for offloading decision. The results from the experiments show that this strategy can already handle different network bandwidth. Hence, this answers another research question: Is more complex offloading strategy justified? For time-sensitive tasks, such as object detection, \gls{slam}, more complex offloading strategy, such as \gls{drl}, will increases the execution latency. For comparison, the simplest object detection model \gls{yolov5}n takes 50.88 ms to do inference on one image, as presented in \cref{tab:inference_time} on the \gls{nuc}. It's reasonable to assume that a \gls{drl} model will use comparable time as well. However, the \gls{rtt} of the edge perception under unconstrained network is less than 100 ms. If a \gls{drl} agent is adopted as the offloading module, the \gls{rtt} can easily increase by 50 percent. In such case, the performance of the object detection task will deteriorate drastically. 

% ---------------------
\section{Limitations}

Since this thesis uses pre-trained object detection models from \gls{yolov5}, only the human obstacles are used to evaluate the \gls{map}. Other obstacles, such as shelves, boxes, pallets, are not considered in the evaluation because they are not in the \gls{coco} dataset and cannot be detected by the pre-trained models accurately. They are only used to increase the complexity of the object detection task. For example, some of the human obstacles are partially occluded by other obstacles. Furthermore, to retrieve ground truth data from \gls{gazebo} simulation, the human obstacles are static in the simulated scenario so that the bounding box sensor from the \gls{gazebo} can generate accurate ground truth data for evaluation. The reason is described in (TODO: add a reference here). 


\section{Future Works}\label{sec:conclusion:limitation_and_future_works}

Foremost, the offloading pipeline is implemented in an open loop manner, i.e., the processed results are not used for downstream applications. For example, the object detection results can be used for obstacle avoidance and local path planning to increase the \gls{amr}'s safety. This will allow the offloading strategy to modify the behavior of the \gls{amr} and create more meaningful metrics for offloading strategies, e.g., how many times the \gls{amr} is collided with an obstacle. In a 

% First, this thesis only considers the scenario where one \gls{amr} offloads to one edge computer to reduce the complexity in evaluation. In real-world application, the \glspl{amr} and edge computers are usually deployed in swarms. Therefore, the \gls{amr} also has to decide to which edge computer it offloads. The one-robot-one-edge-computer also simplify

